\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsfonts}
\usepackage{bbm}
\usepackage{amssymb}
\usepackage[margin=2cm]{geometry}
\usepackage{graphicx}
\graphicspath{ {images/} }
\providecommand{\norm}[1]{\lVert#1\rVert}
\usepackage{fullpage,enumitem,amssymb,amsmath,xcolor,cancel,gensymb,hyperref,graphicx}
\usepackage{indentfirst}
\setlength{\parskip}{1em}

%\begin{align*}…\end{align*} if you want to fit an equation. 
%FOR PICTURES: include graphicsx 
%\includegraphics[scale=x]{name}
%double space and write caption in the center classshe 

\title{Clase 14: Aprendizaje Convexo}
\author{María José Sedano Castañeda}
\date{Marzo 04, 2021}


\begin{document}

\maketitle

\section{Introducción}

El aprendizaje convexo es muy útil, pues el marco de trabajo que nos brinda hace que lo que hemos desarrollado funcione bien, además tenemos algoritmos eficientes para resolver problemas en este contexto. 

\section{Previo}
\textbf{Problemas Convexos} regresión lineal (variable de respuesta continua), regresión logística

Argumentamos que los problemas anteriores son convexos, su función de pérdida asociada es convexa.

\textbf{Problemas no Convexos} clasificación con hiperplanos.

Este problema tiene una función de pérdida no convexa, la cual está carcterizada como una función 0-1 donde:
$$l(<w,x>,y)= \mathbbm{1}_{[y\neq signo]}$$ 
Es decir, hacer la predicción con una transformación lineal para predecir una etiqueta está descrita como la pérdida de haber realizado una mala clasificación.
\section{Caracterización de un problema convexo}
Desde este enfoque caracterizaremos un problema de aprendizaje convexo:

\textbf{Función de Pérdida:} Es una función convexa que tiene buenas propiedades para un algoritmo de optimización.

\textbf{Clase de Hipótesis:} Debe ser un conjunto convexo.

En este sentido también necesitaremos:
\begin{itemize}
    \item Criterios de continuidad para la función de pérdida $l$.
    \item Caracterización de convexidad en funciones de pérdida.
\end{itemize}

A continuación daremos un marco teórico necesario para unificar definiciones sobre convexidad. 

\section{Nociones de Convexidad}
\textbf{Definición 1} Un conjunto $C$ es convexo si $\forall x_{1},x_{2} \in C$ y   $\alpha \in [0,1]$ entonces $\alpha x_{1}+ (1-\alpha)x_{2} \in C $.

\begin{figure}[h]
\caption{Ejemplos de conjuntos convexos}
\centering
\includegraphics[width=0.5\textwidth]{im1_convexidad_clase14.png}
\end{figure}

La interpretación gráfica de esta definición es que un conjunto es \textbf{convexo} si, dados dos puntos de un conjunto, todo punto del segmento de recta que une a estos dos puntos es también un miembro del conjunto. 

\textbf{Definición 2} Una función $f$ es convexa si $f:C\rightarrow \mathbb{R}$ donde $C$ es un conjunto convexo y $\forall x_{1},x_{2} \in C$ y $t \in [0,1]$ tenemos:
$$f(t x_{1}+(1-t)x_{2})\leq t f(x_{1})+(1-t)f(x_{2})$$
\begin{figure}[h]
\caption{Función Convexa}
\centering
\includegraphics[width=0.5\textwidth]{im2_convexidad_clase14.png}
\end{figure}

\textbf{Definición 3 (alternativa)} Si definimos el epígrafo de la función $f$ como:
$$epi(f)=\{(x,\beta): f(x)\leq \beta\}$$
Entonces $f$ es convexa si y solo si $epi(f)$ es un conjunto convexo.

\newpage
La propiedad de la convexidad toma relevancia porque nuestro objetivo es buscar una hipótesis que al cumplirse minimice la función de riesgo empírico. Con respecto a esto tenemos la siguiente proposición:

\textbf{Proposición 1.} Todo mínimo local de una función convexa es un mínimo global.

(\textit{La demostración a esta proposición se encuentra más adelante})

Para modelos más complicados que la regresión lineal no hay una solución analítica para encontrar el minimizador de la función de pérdida bajo una familia de hipótesis, por lo que es necesario implementar métodos iterativos de búsqueda para encontrar el mínimo. La convexidad garantiza que existe un mínimo global en donde el algoritmo de búsqueda anterior se estanque, así llegaremos al mejor punto.

Por otro lado, la optimización de las funciones convexas nos da un buen marco de referencia para probar distintos algoritmos de optimización, de modo que si dicho algoritmo no funciona bien para problemas convexos podemos descartarlo para problemas no convexos.

\textbf{Definición 4.} Sea $B(u,r)=\{v:\norm{v-u}\leq r\}$. Decimos que $f(u)$ es un mínimo local de $f$ en $u$ si $\exists r>0 $ tal que $\forall v \in B(u,r)$ tenemos $f(u)\leq f(v)$.

\textbf{Demostración (Proposición 1)}
\newline
\\Tomamos $v, \exists \alpha>0$ tal que $u+\alpha (v-u) \in B(u,r)$ \begin{align*}
     \rightarrow f(u)&\leq f(u+\alpha(v-u))\\
     &=f(\alpha v + (1-\alpha) u)\\
     &\leq \alpha f(v)+ (1-\alpha) f(u)\\
     &\leq f(v)\\
     \rightarrow f(u)&\leq f(v)
\end{align*}
\begin{center}
$\therefore u$ es un mínimo global.   
\end{center}
\textbf{Observación:} Esta proposición no requiere que $v\in B(u,r)$ si no que funciona para todo punto en el dominio.  

\textbf{Propiedad 1} Dada $f$ como la hemos definido tenemos que $f(y)\geq f(x) + \nabla f^{T}(x)(y-x)$ considerando a $x,y \in C$ donde C es un conjunto convexo.
\begin{figure}[h]
\caption{Propiedad 1}
\centering
\includegraphics[width=0.4\textwidth]{im3_convexidad_clase14.png}
\end{figure}
\newpage
\textbf{Lema 1.} Sea $f:\mathbb{R}\rightarrow \mathbb{R}$ dos veces diferenciable. Las siguientes afirmaciones son equivalentes: 
\begin{enumerate}
    \item $f$ es convexa.
    \item $f'$ es monótona no decreciente.
    \item $f''$ es no negativa.
\end{enumerate}

\textbf{Proposición 2.}  Si $f:\mathbb{R}^{d}\rightarrow \mathbb{R}$ tal que $f(w)=g(<w,x>+b)$ tal que $w \in \mathbb{R}^{d}$, $b\in\mathbb{R}$ y $g:\mathbb{R}\rightarrow \mathbb{R}$. Entonces si $g$ es convexa también $f$ es convexa.

\textbf{Proposición 3.} Sea $f_{i}:\mathbb{R}^{d}\rightarrow\mathbb{R}$, con $i=\{1,2,...,r\}$ considerando que cada $f_{i}$ es convexa. Entonces:
\begin{itemize}
    \item $g(x)=\max\limits_{i} f_{i}$ es convexa.
    \item $g(x)=\sum_{i} w_{i}f_{i}(x)$ donde $w_{i}\geq 0$ es convexa.
\end{itemize}
\textbf{Observación} La proposición anterior puede usarse para las funciones de pérdida, tomando el promedio ponderado de las mismas.


\textbf{Definición 5.} Sea $C\subseteq\mathbb{R}^{d}$. Una función $f:\mathbb{R}^{d}\rightarrow\mathbb{R}^{k}$ es $\rho-Lipschitz$ en $C$ si $\forall u,v \in C$ tenemos que $$\norm{f(u)-f(v)}\leq \rho \norm{u-v}$$
\textbf{Interpretación.} La definición anterior es una noción sobre el comportamiento de las funciones, establece que no hay "cambios bruscos", esto se traduce en que la función no es numéricamente inestable.

\textbf{Definición 6} Decimos que una función $f:\mathbb{R}^{d}\rightarrow\mathbb{R}$ diferenciable es $\beta-suave$ si el gradiente es $\beta$ Lipschitz
$$\norm{\nabla f(u)-\nabla f(v)}\leq\beta\norm{u-v}$$
\textbf{Interpretación} La definición anterior es útil para decir que no esperamos "cambios bruscos" o cambios acotados en el gradiente de a función ante cambios en el dominio.

\textbf{Corolario 1} Una función convexa que es $\beta-suave$ satisface:
$$f(u)\leq f(w)+\nabla f^{T}(w)(u-w)+\frac{\beta}{2}\norm{u-w}^{2}$$
Lo anterior implica que una función convexa y $\beta-suave$ se puede acotar por arriba y por abajo.

\section{Problemas de Aprendizaje Convexo}
$H=$ es un espacio de hipótesis arbitrario.

\ Vamos a identificar cada elemento de $h\in H $ con un vector de parámetros:
$$h(x)=w^{T}x \rightarrow h_{w}$$
Podemos pensar en $H\subseteq \mathbb{R}^{p}$ cuando $w\in \mathbb{R}^{p}$

Entonces la función de pérdida evaluada en la hipótesis la podemos identificar como:
$$l(h,z)=l(h_{w},z)=l(w,z)$$

Entonces nuestro objetivo era encontrar una $h^{*}$ tal que:
$$h^{*}=\min\limits_{h \in H} l(h,z)=\min\limits_{w \in \mathbb{R}^{p} } l(w,z)$$


\textbf{Definición 7} Un problema de aprendizaje $(H,Z,l)$ es convexo si $H$ es un conjunto convexo y $l(.,z)$ es una función convexa.

\textbf{Ejemplo} Regresión lineal:
$$h_{w}(x)=<w,x> \rightarrow l(w,(x,y))=(<w,x>-y)^{2}$$

\textbf{Lema 2.} El problema de minimización de riesgo empírico (ERM) es un problema de aprendizaje convexo si $H$ es un conjunto convexo y $l(.,z)$ es una función convexa.\

Es importante notar que un problema de aprendizaje convexo no garantiza un "buen desempeño", es decir que el error de generalización va a estar acotado y así tener un clasificación con alta precisión. 

\textbf{Definición 8} \textit{ (Problema CLA- Convexo Lipschitz-Acotado)}
\ Un problema de aprendizaje $(H,Z,l)$ es CLA si $H$ es convexo y $\forall w \in H$ $\norm{w}\leq B$ además $\forall z\in Z$ $l(.,z)$ es convexa y $\rho-Lipschitz$.

\textbf{Definición 9} \textit{ (Problema CSA- Convexo-Suave-Acotado)}
\ Un problema de aprendizaje $(H,Z,l)$ es CSA si $H$ es convexo y $\forall w \in H$ $\norm{w}\leq B$ además $\forall z\in Z$ $l(.,z)$ es convexa, no negativa y $\beta-Suave$.

\\Estas dos definiciones anteriores trazarán una ruta para garantizar que estos problemas sean aprendibles.

\section{Funciones de Pérdida Sustituto}
Hemos visto a lo largo del desarrollo que existen funciones de pérdida no convexas, por ejemplo, la función de pérdida $0-1$. Para esto introducimos las \textbf{funciones de pérdida sustituto} las cuales tienen como objetivo acotar la función de pérdida original y con esto garantizaremos resolver el problema al menos aproximadamente.

\textbf{Ejemplo}
$$l^{0}(w,(x,y))=\mathbb{I}_{[y\neq signo(w^{T}x)]}$$
Necesitamos:
\begin{enumerate}
    \item una función convexa
    \item una función que acote la función de pérdida original
\end{enumerate}
Para nuestra función podemos definir a la \textbf{Función de pérdida de Hinge} como:
$$l^{h}(w,(x,y))=max\{0,1-y<x,w>\}$$
Se observa que:
$$l^{0}(w,(x,y))\leq l^{h}(w,(x,y))$$
\newpage
\begin{figure}[h]
\caption{Ejemplo función de pérdida sustituto }
\centering
\includegraphics[width=0.5\textwidth]{80207.jpg}
\end{figure}
Queremos acotar por arriba la función de pérdida original porque si tenemos:
\begin{align*}
     L^{h}_{D}(A(s))&\leq \min\limits_{w \in H} L^{h}_{D}(w) + \epsilon\\
     L^{0}_{D}(A(s))&\leq \min\limits_{w \in H} L^{h}_{D}(w) + \epsilon\\
     &= \min\limits_{w \in H} L^{0}_{D}(w)+\min\limits_{w \in H} L^{h}_{D}(w)-\min\limits_{w \in H} L^{0}_{D}(w)+\epsilon \\
\end{align*}
Notemos en esta última igualdad que el primer término $\min\limits_{w \in H} L^{0}_{D}(w)$ representa el error de aproximación, la diferencia del segundo menos el tercer término $$\min\limits_{w \in H} L^{h}_{D}(w)-\min\limits_{w \in H} L^{0}_{D}(w)$$ representa el error de Optimización, mientras que el último término $\epsilon$ es el error de estimación ya conocido.\\


\end{document}
